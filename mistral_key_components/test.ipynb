{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "# This Class ignores some MOE components in the original model for testing purposes\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    dim: int = 128\n",
    "    n_layers: int = 4\n",
    "    n_heads: int = 8  # number of heads for the Q\n",
    "    n_kv_heads: Optional[int] = None  # number of heads for the K and V\n",
    "    vocab_size: int = 1000\n",
    "    multiple_of: int = 256  # feedforward dimension must be multiple of this\n",
    "    ffn_dim_multiplier: Optional[float] = None\n",
    "    norm_eps: float = 1e-5\n",
    "    device: str = None\n",
    "    # for KV Cache\n",
    "    max_batch_size: int = 32\n",
    "    max_seq_len: int = 512\n",
    "\n",
    "\n",
    "def precompute_freqs_pos_frequencis(head_dim: int, seq_len: int, device: str, theta: float = 10000.0) -> torch.Tensor:\n",
    "    assert head_dim % 2 == 0, \"head_dim must be even as proposed in https://arxiv.org/pdf/2104.09864\"\n",
    "    # theta parameter = a sequence according to the paper\n",
    "    # theta_i = 10000^(-2(i-1)/dim) for i in range(1, dim / 2 + 1)\n",
    "    # shape (both theta_denominator and theta): (head_dim / 2)\n",
    "    theta_numerator = torch.arange(0, head_dim, 2).float()\n",
    "    theta = 1.0 / (theta ** (theta_numerator / head_dim)).to(device)\n",
    "    # build the \"m\" in the paper (aka the positions)\n",
    "    # shape: (seq_len)\n",
    "    m = torch.arange(seq_len, device=device)\n",
    "    # Multiply each theta by each position using the outer product (for all possible combinations of the two)\n",
    "    # Shape: (Seq_Len) outer_product* (Head_Dim / 2) -> (Seq_Len, Head_Dim / 2)\n",
    "    freqs = torch.outer(m, theta).float()\n",
    "    # Compute the complex number polar form: c = R * exp(m * theta) w/ R = 1\n",
    "    # (seq_len, head_dim / 2) -> (seq_len, head_dim / 2)\n",
    "    freqs_complex = torch.polar(torch.ones_like(freqs), freqs)\n",
    "    return freqs_complex\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, args: ModelArgs):\n",
    "        super().__init__()\n",
    "        assert args.vocab_size > 0, \"vocab size should be set\"\n",
    "        self.args = args\n",
    "        self.vocab_size = args.vocab_size\n",
    "        self.n_layers = args.n_layers\n",
    "        # input embedding\n",
    "        self.tok_embeddings = nn.Embedding(args.vocab_size, args.dim)\n",
    "        # each transformer layers in (Nx part) of the model, total self.n_layers blocks\n",
    "        self.layers = nn.ModuleList([TransformerBlock(args=args) for _ in range(args.n_layers)])\n",
    "        # RMS Normalization (better than LayerNorm) - used in Llama and Mistral\n",
    "        self.norm = RMSNorm(args.dim, eps=args.norm_eps)    # eps for numerical stability never divided by 0\n",
    "        # output layer\n",
    "        self.output = nn.Linear(args.dim, args.vocab_size, bias=False)\n",
    "        # precomputed frequencies for ROPE positional encoding (https://arxiv.org/pdf/2104.09864)\n",
    "        # Shapes: (max_seq_len * 2, head_dim / 2)\n",
    "        self.freqs_complex = precompute_freqs_pos_frequencis(   # to precompute the sin and cos in the paper\n",
    "            self.args.dim // self.args.n_heads, self.args.max_seq_len * 2, device=self.args.device\n",
    "        )\n",
    "\n",
    "    def forward(self, tokens: torch.Tensor, start_pos: int) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        note that with the KV Cache, only need the latest tokens, no need all tokens: info about previous tokens are saved in the cache\n",
    "        NOTE: this is only for inference, not training (in training there's no KV cache)\n",
    "        \"\"\"\n",
    "        # (B, Seq_len)\n",
    "        batch_size, seq_len = tokens.shape\n",
    "        assert seq_len == 1, \"One token at a time at inference time\"\n",
    "\n",
    "        # (B, Seq_len) -> (B, Seq_len, dim)\n",
    "        h = self.tok_embeddings(tokens)\n",
    "\n",
    "        # Retrieve the pairs (m, theta) corresponding to the positions [start_pos, start_pos + seq_len]\n",
    "        freqs_complex = self.freqs_complex[start_pos:start_pos + seq_len]\n",
    "\n",
    "        # Apply precomputed frequencies to the encoding layers for positional encoding\n",
    "        for layer in self.layers:\n",
    "            h = layer(h, freqs_complex, start_pos, None)    # these are the Nx TransformerBlock layers\n",
    "\n",
    "        # Apply RMS Normalization after all layers\n",
    "        h = self.norm(h)\n",
    "\n",
    "        # Output layer\n",
    "        output = self.output(h)\n",
    "        return output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T18:18:30.797572Z",
     "start_time": "2024-05-26T18:18:30.793703Z"
    }
   },
   "id": "a0f9f87ea8ec6dc"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "args = ModelArgs()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T18:18:31.141772Z",
     "start_time": "2024-05-26T18:18:31.136029Z"
    }
   },
   "id": "ed51eb8a774762ed"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_seq_len: 512\n",
      "Head_dim: 16\n",
      "Freqs_complex shape: torch.Size([1024, 8])\n"
     ]
    }
   ],
   "source": [
    "print(\"Max_seq_len:\", args.max_seq_len)\n",
    "print(\"Head_dim:\", args.dim // args.n_heads)\n",
    "print(\"Freqs_complex shape:\",   # should be (max_seq_len * 2, head_dim / 2)\n",
    "      precompute_freqs_pos_frequencis(args.dim // args.n_heads, args.max_seq_len * 2, args.device).shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T18:18:31.488583Z",
     "start_time": "2024-05-26T18:18:31.483242Z"
    }
   },
   "id": "cdb2986f6cc77b91"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([12, 4])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.zeros((12, 4))\n",
    "tensor.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T18:28:49.828917Z",
     "start_time": "2024-05-26T18:28:49.823911Z"
    }
   },
   "id": "b0ac3acfb21ef118"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 12, 4])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.unsqueeze(0).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T18:29:27.772992Z",
     "start_time": "2024-05-26T18:29:27.768587Z"
    }
   },
   "id": "dac705f1ecd8b5c6"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 12, 1, 4])"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.unsqueeze(0).unsqueeze(2).shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T18:29:35.304659Z",
     "start_time": "2024-05-26T18:29:35.302018Z"
    }
   },
   "id": "67f803d47a40f81d"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([2, 5, 3, 4])\n",
      "Complex tensor shape: torch.Size([2, 5, 3, 2])\n",
      "Expanded frequencies tensor shape: torch.Size([1, 5, 1, 2])\n",
      "Rotated complex tensor shape: torch.Size([2, 5, 3, 2])\n",
      "Real tensor shape: torch.Size([2, 5, 3, 2, 2])\n",
      "Flattened tensor shape: torch.Size([2, 5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example input tensor (B=batch_size, seq_len=sequence_length, H=number_of_heads, head_dim=dimension_per_head)\n",
    "x = torch.randn(2, 5, 3, 4)\n",
    "\n",
    "# Example frequencies tensor (complex numbers)\n",
    "freqs_complex = torch.randn(5, 2)  # Assuming 5 frequencies with real and imaginary parts\n",
    "\n",
    "# Step 1: Reshaping the input tensor into complex numbers\n",
    "x_complex = torch.view_as_complex(x.float().reshape(*x.shape[:-1], -1, 2))\n",
    "\n",
    "# Step 2: Expanding the frequencies tensor to match the shape of the input tensor\n",
    "freqs_complex_expanded = freqs_complex.unsqueeze(0).unsqueeze(2)\n",
    "\n",
    "# Step 3: Element-wise multiplication of complex tensors\n",
    "x_rotated = x_complex * freqs_complex_expanded\n",
    "\n",
    "# Step 4: Converting complex tensor to real tensor\n",
    "x_real = torch.view_as_real(x_rotated)\n",
    "\n",
    "# Step 5: Flattening the tensor\n",
    "x_flattened = x_real.reshape(*x.shape)\n",
    "\n",
    "# Printing shapes to visualize the transformations\n",
    "print(\"Input tensor shape:\", x.shape)\n",
    "print(\"Complex tensor shape:\", x_complex.shape)\n",
    "print(\"Expanded frequencies tensor shape:\", freqs_complex_expanded.shape)\n",
    "print(\"Rotated complex tensor shape:\", x_rotated.shape)\n",
    "print(\"Real tensor shape:\", x_real.shape)\n",
    "print(\"Flattened tensor shape:\", x_flattened.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T18:34:33.158423Z",
     "start_time": "2024-05-26T18:34:33.146822Z"
    }
   },
   "id": "91b40af27196e183"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 4.0634e-01,  6.5052e-01, -4.0613e-01, -1.6863e+00],\n",
      "          [-1.6818e-01,  5.2302e-01,  4.5995e-02,  7.1850e-01],\n",
      "          [ 1.3306e+00,  8.8058e-01,  1.1169e+00, -1.4236e+00]],\n",
      "\n",
      "         [[-1.7608e+00,  6.0484e-01, -2.2931e-01,  1.3687e-01],\n",
      "          [-1.3313e+00,  8.4889e-01, -8.2096e-01, -2.0487e+00],\n",
      "          [-1.1707e+00,  3.7725e-01,  3.5198e-01, -1.2474e+00]],\n",
      "\n",
      "         [[ 2.2884e+00,  2.3790e-01,  6.6371e-01,  1.4763e-01],\n",
      "          [ 1.1743e-01, -1.0336e-01,  7.8413e-02,  2.1786e-02],\n",
      "          [ 9.4651e-01,  3.9243e-01, -1.0347e+00,  2.4265e+00]],\n",
      "\n",
      "         [[ 7.2945e-01, -1.3962e+00, -2.6405e-01, -5.2072e-01],\n",
      "          [-6.5911e-01,  2.2563e-02, -8.1039e-01, -1.0036e+00],\n",
      "          [-1.2535e+00, -1.9269e-01,  1.4061e-01,  8.7562e-01]],\n",
      "\n",
      "         [[-3.5871e-01, -2.0886e+00, -5.3053e-01,  1.2392e+00],\n",
      "          [-1.9687e+00, -4.9926e-01, -5.2410e-01,  5.0675e-02],\n",
      "          [-7.1429e-01, -6.9997e-01, -1.2316e+00, -5.7057e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2621e+00,  3.5530e-01,  9.8895e-02, -5.7314e-01],\n",
      "          [ 5.7557e-01,  4.5370e-01, -5.7483e-01,  1.0765e-01],\n",
      "          [ 1.1296e-01, -3.6985e-01,  6.1271e-01,  1.0720e-02]],\n",
      "\n",
      "         [[-1.1302e+00, -4.2102e-01,  1.2376e+00,  6.7158e-01],\n",
      "          [-1.5826e+00, -3.6141e-01,  9.3052e-01,  1.5718e-01],\n",
      "          [-6.4927e-01, -3.4903e-01, -3.7152e-01, -1.0856e+00]],\n",
      "\n",
      "         [[-2.2591e-02,  7.1405e-01, -2.0204e-01,  1.8406e+00],\n",
      "          [-1.7134e+00,  1.4961e+00,  4.8554e-02,  2.2948e+00],\n",
      "          [-2.6021e-01,  3.0603e-01,  1.8944e+00, -4.0025e-01]],\n",
      "\n",
      "         [[-1.5424e-01, -7.5500e-01,  2.0348e+00,  1.9567e+00],\n",
      "          [ 6.7149e-01, -6.1286e-01, -1.7548e+00,  9.3869e-02],\n",
      "          [ 1.0657e+00,  1.5487e-01, -8.3339e-01,  1.7333e+00]],\n",
      "\n",
      "         [[-3.8887e-01,  7.4453e-02,  4.7792e-01, -1.1408e+00],\n",
      "          [ 1.6785e+00,  4.3963e-01, -2.7859e-01,  6.4984e-01],\n",
      "          [-2.0323e-01,  9.2365e-04, -6.0629e-01,  3.2979e+00]]]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T18:39:52.061276Z",
     "start_time": "2024-05-26T18:39:52.051480Z"
    }
   },
   "id": "5a440a4a94bb290b"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.4063+6.5052e-01j, -0.4061-1.6863e+00j],\n",
      "          [-0.1682+5.2302e-01j,  0.0460+7.1850e-01j],\n",
      "          [ 1.3306+8.8058e-01j,  1.1169-1.4236e+00j]],\n",
      "\n",
      "         [[-1.7608+6.0484e-01j, -0.2293+1.3687e-01j],\n",
      "          [-1.3313+8.4889e-01j, -0.8210-2.0487e+00j],\n",
      "          [-1.1707+3.7725e-01j,  0.3520-1.2474e+00j]],\n",
      "\n",
      "         [[ 2.2884+2.3790e-01j,  0.6637+1.4763e-01j],\n",
      "          [ 0.1174-1.0336e-01j,  0.0784+2.1786e-02j],\n",
      "          [ 0.9465+3.9243e-01j, -1.0347+2.4265e+00j]],\n",
      "\n",
      "         [[ 0.7295-1.3962e+00j, -0.2640-5.2072e-01j],\n",
      "          [-0.6591+2.2563e-02j, -0.8104-1.0036e+00j],\n",
      "          [-1.2535-1.9269e-01j,  0.1406+8.7562e-01j]],\n",
      "\n",
      "         [[-0.3587-2.0886e+00j, -0.5305+1.2392e+00j],\n",
      "          [-1.9687-4.9926e-01j, -0.5241+5.0675e-02j],\n",
      "          [-0.7143-6.9997e-01j, -1.2316-5.7057e-01j]]],\n",
      "\n",
      "\n",
      "        [[[-1.2621+3.5530e-01j,  0.0989-5.7314e-01j],\n",
      "          [ 0.5756+4.5370e-01j, -0.5748+1.0765e-01j],\n",
      "          [ 0.1130-3.6985e-01j,  0.6127+1.0720e-02j]],\n",
      "\n",
      "         [[-1.1302-4.2102e-01j,  1.2376+6.7158e-01j],\n",
      "          [-1.5826-3.6141e-01j,  0.9305+1.5718e-01j],\n",
      "          [-0.6493-3.4903e-01j, -0.3715-1.0856e+00j]],\n",
      "\n",
      "         [[-0.0226+7.1405e-01j, -0.2020+1.8406e+00j],\n",
      "          [-1.7134+1.4961e+00j,  0.0486+2.2948e+00j],\n",
      "          [-0.2602+3.0603e-01j,  1.8944-4.0025e-01j]],\n",
      "\n",
      "         [[-0.1542-7.5500e-01j,  2.0348+1.9567e+00j],\n",
      "          [ 0.6715-6.1286e-01j, -1.7548+9.3869e-02j],\n",
      "          [ 1.0657+1.5487e-01j, -0.8334+1.7333e+00j]],\n",
      "\n",
      "         [[-0.3889+7.4453e-02j,  0.4779-1.1408e+00j],\n",
      "          [ 1.6785+4.3963e-01j, -0.2786+6.4984e-01j],\n",
      "          [-0.2032+9.2365e-04j, -0.6063+3.2979e+00j]]]])\n"
     ]
    }
   ],
   "source": [
    "print(x_complex)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T18:39:52.569344Z",
     "start_time": "2024-05-26T18:39:52.563275Z"
    }
   },
   "id": "232dcb0c62bda044"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "input_tensor = torch.tensor([\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]],\n",
    "    [[9, 10], [11, 12]]\n",
    "])\n",
    "\n",
    "# Define the Dim vector\n",
    "Dim = torch.tensor([2, 2])\n",
    "Expanded_Dim = Dim.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "# Perform element-wise multiplication\n",
    "assert(input_tensor * Expanded_Dim == input_tensor * Dim).all()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T19:29:21.654103Z",
     "start_time": "2024-05-26T19:29:21.646243Z"
    }
   },
   "id": "c0a355b10d6cb743"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([3, 2, 2])\n",
      "Reshaped Seq_Len shape: torch.Size([3, 1, 1])\n",
      "Expanded Seq_Len shape: torch.Size([1, 1, 3])\n",
      "Result tensor shape: torch.Size([3, 2, 2])\n",
      "tensor([[[ 2,  4],\n",
      "         [ 6,  8]],\n",
      "\n",
      "        [[15, 18],\n",
      "         [21, 24]],\n",
      "\n",
      "        [[36, 40],\n",
      "         [44, 48]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define the input tensor (B, Seq_Len, Dim)\n",
    "input_tensor = torch.tensor([\n",
    "    [[1, 2], [3, 4]],\n",
    "    [[5, 6], [7, 8]],\n",
    "    [[9, 10], [11, 12]]\n",
    "])\n",
    "\n",
    "# Define the one-dimensional tensor Seq_Len\n",
    "Seq_Len = torch.tensor([2, 3, 4])  # Example values for Seq_Len\n",
    "\n",
    "# Reshape or expand Seq_Len to match the shape of the input tensor\n",
    "# You can choose one of the following approaches:\n",
    "\n",
    "# Approach 1: Reshape Seq_Len to have the same number of dimensions as the input tensor\n",
    "reshaped_Seq_Len = Seq_Len.unsqueeze(-1).unsqueeze(-1)  # Reshape to (Seq_Len, 1, 1)\n",
    "\n",
    "# Approach 2: Expand Seq_Len to match the shape of the input tensor\n",
    "expanded_Seq_Len = Seq_Len.unsqueeze(0).unsqueeze(0)  # Expand to (1, 1, Seq_Len)\n",
    "\n",
    "# Perform element-wise multiplication between the reshaped or expanded Seq_Len and the input tensor\n",
    "result_tensor = input_tensor * reshaped_Seq_Len  # or expanded_Seq_Len\n",
    "\n",
    "print(\"Input tensor shape:\", input_tensor.shape)\n",
    "print(\"Reshaped Seq_Len shape:\", reshaped_Seq_Len.shape)\n",
    "print(\"Expanded Seq_Len shape:\", expanded_Seq_Len.shape)\n",
    "print(\"Result tensor shape:\", result_tensor.shape)\n",
    "print(result_tensor) "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T19:32:54.802305Z",
     "start_time": "2024-05-26T19:32:54.790443Z"
    }
   },
   "id": "6280c31ce77232ff"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T19:31:54.784426Z",
     "start_time": "2024-05-26T19:31:54.772915Z"
    }
   },
   "id": "f5731a4aa5ef4888"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f5b81cc51eaa14e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5aa5a8de88a1b870"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "194ceeeda40b0db6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8776ea131a6e8a2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2df46ab1acc6bcf7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "425aebb50a2a134e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "bee15573ed4190be"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "71c837e22e97bbc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "35413a99f4533494"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "66caf71b2585afaa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c8784a170851288d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reach here 0 0 \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BufferCache' object has no attribute 'mask'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m encoded_prompts \u001B[38;5;241m=\u001B[39m [[\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m7\u001B[39m], [\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m9\u001B[39m, \u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m, \u001B[38;5;241m6\u001B[39m, \u001B[38;5;241m9\u001B[39m]]\n\u001B[0;32m----> 2\u001B[0m generated_sequences \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoded_prompts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoded_prompts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtransformer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.8\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m    \u001B[49m\u001B[43meos_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Replace with an appropriate eos_id if available\u001B[39;49;00m\n\u001B[1;32m      8\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/llm/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/_DataScience/GitHub/Mistral/Mistral_From_Scratch/mistral_inference/generate.py:73\u001B[0m, in \u001B[0;36mgenerate\u001B[0;34m(encoded_prompts, model, max_tokens, temperature, chunk_size, eos_id)\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreach here 0 0 \u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     72\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m s \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m0\u001B[39m, max_prompt_len, chunk_size):\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreach here 1 \u001B[39m\u001B[38;5;124m\"\u001B[39m, s, \u001B[43mcache\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmask\u001B[49m)\n\u001B[1;32m     74\u001B[0m     \u001B[38;5;66;03m# Split encoded prompts into chunks of size chunk_size\u001B[39;00m\n\u001B[1;32m     75\u001B[0m     prompt_chunks \u001B[38;5;241m=\u001B[39m [p[s : s \u001B[38;5;241m+\u001B[39m chunk_size] \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m encoded_prompts]\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'BufferCache' object has no attribute 'mask'"
     ]
    }
   ],
   "source": [
    "encoded_prompts = [[1, 2, 3, 1, 2, 5, 7], [4, 5, 6, 9, 4, 5, 6, 9]]\n",
    "generated_sequences = generate(\n",
    "    encoded_prompts=encoded_prompts,\n",
    "    model=transformer,\n",
    "    max_tokens=20,\n",
    "    temperature=0.8,\n",
    "    eos_id=None  # Replace with an appropriate eos_id if available\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T03:48:34.350373Z",
     "start_time": "2024-05-26T03:48:34.211363Z"
    }
   },
   "id": "824dac3c6bade7b3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T03:46:42.830351Z",
     "start_time": "2024-05-26T03:46:42.825801Z"
    }
   },
   "id": "3910119176319c52"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hshape torch.Size([2048, 128])\n"
     ]
    }
   ],
   "source": [
    "# input_ids need to be a tensor of shape torch.Size([args.dim * args.max_batch_size])\n",
    "# each entry need to be within range [0, args.vocab_size - 1]\n",
    "input = torch.tensor([args.vocab_size - 1] * (args.dim * args.max_batch_size))\n",
    "seqlens = [args.dim] * args.max_batch_size  # Assuming all sequences are of maximum length for simplicity\n",
    "output = transformer(input, seqlens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T03:46:43.477403Z",
     "start_time": "2024-05-26T03:46:43.337211Z"
    }
   },
   "id": "f16bb75944de3f0e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2048])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T03:46:44.346507Z",
     "start_time": "2024-05-26T03:46:44.341617Z"
    }
   },
   "id": "89339f97ce6b4c09"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2048, 100])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T03:46:44.926145Z",
     "start_time": "2024-05-26T03:46:44.921556Z"
    }
   },
   "id": "47a1bd5941f6c15d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "pred = sample(output, temperature=0.8, top_p=0.9)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T03:46:45.454766Z",
     "start_time": "2024-05-26T03:46:45.446390Z"
    }
   },
   "id": "c7aec2613780a99c"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2048])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T03:46:45.873411Z",
     "start_time": "2024-05-26T03:46:45.869982Z"
    }
   },
   "id": "ac0a00b73c53fc2e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T03:48:14.215468Z",
     "start_time": "2024-05-26T03:48:14.204015Z"
    }
   },
   "id": "31e5fadcabe9d269"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T03:23:17.631480Z",
     "start_time": "2024-05-26T03:23:17.627635Z"
    }
   },
   "id": "267f81c231716ba9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "44cabbacd905449"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9ec0716b145dd468"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ae86bade5b37ff8c"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def visualize_token_flow(tokens, attention_matrix):\n",
    "    dot = Digraph(comment='Token Flow')\n",
    "\n",
    "    # Adding nodes for each token\n",
    "    for i, token in enumerate(tokens):\n",
    "        dot.node(str(i), token)\n",
    "\n",
    "    # Adding edges based on attention scores\n",
    "    # Assuming attention_matrix is a square matrix with dimensions (len(tokens), len(tokens))\n",
    "    for i in range(len(tokens)):\n",
    "        for j in range(len(tokens)):\n",
    "            # Add edges with labels of attention scores\n",
    "            # Thresholding attention to avoid clutter, only show significant attention flows\n",
    "            if attention_matrix[i][j] > 0.1:  # threshold can be adjusted\n",
    "                dot.edge(str(j), str(i), label=f'{attention_matrix[i][j]:.2f}')\n",
    "\n",
    "    print(dot.source)  # optionally print the DOT source code for debugging\n",
    "    dot.render('token_flow', format='png', cleanup=True)\n",
    "    return dot"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T02:26:39.365230Z",
     "start_time": "2024-05-26T02:26:39.349491Z"
    }
   },
   "id": "a8ef2857d6149e8a"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Token Flow\n",
      "digraph {\n",
      "\t0 [label=Hello]\n",
      "\t1 [label=world]\n",
      "\t2 [label=this]\n",
      "\t3 [label=is]\n",
      "\t4 [label=a]\n",
      "\t5 [label=test]\n",
      "\t1 -> 0 [label=0.20]\n",
      "\t1 -> 1 [label=0.30]\n",
      "\t2 -> 2 [label=0.50]\n",
      "\t3 -> 2 [label=0.20]\n",
      "\t2 -> 3 [label=0.20]\n",
      "\t3 -> 3 [label=0.60]\n",
      "\t4 -> 4 [label=0.60]\n",
      "\t5 -> 5 [label=0.70]\n",
      "}\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.50.0 (0)\n -->\n<!-- Pages: 1 -->\n<svg width=\"460pt\" height=\"131pt\"\n viewBox=\"0.00 0.00 460.20 131.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 127)\">\n<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-127 456.2,-127 456.2,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"31.2\" cy=\"-18\" rx=\"30.59\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"31.2\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Hello</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"31.2\" cy=\"-105\" rx=\"31.4\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"31.2\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">world</text>\n</g>\n<!-- 1&#45;&gt;0 -->\n<g id=\"edge1\" class=\"edge\">\n<title>1&#45;&gt;0</title>\n<path fill=\"none\" stroke=\"black\" d=\"M31.2,-86.8C31.2,-75.16 31.2,-59.55 31.2,-46.24\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"34.7,-46.18 31.2,-36.18 27.7,-46.18 34.7,-46.18\"/>\n<text text-anchor=\"middle\" x=\"43.7\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">0.20</text>\n</g>\n<!-- 1&#45;&gt;1 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"black\" d=\"M59.51,-112.83C70.86,-113.27 80.39,-110.66 80.39,-105 80.39,-101.2 76.09,-98.77 69.82,-97.72\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"69.68,-94.21 59.51,-97.17 69.31,-101.2 69.68,-94.21\"/>\n<text text-anchor=\"middle\" x=\"92.89\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.30</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"152.2\" cy=\"-105\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"152.2\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">this</text>\n</g>\n<!-- 2&#45;&gt;2 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M176.73,-112.75C187.71,-113.49 197.2,-110.91 197.2,-105 197.2,-101.03 192.91,-98.56 186.77,-97.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"186.84,-94.09 176.73,-97.25 186.6,-101.09 186.84,-94.09\"/>\n<text text-anchor=\"middle\" x=\"209.7\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.50</text>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"129.2\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"129.2\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">is</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge5\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M133,-92.07C125.33,-86.17 117.35,-78.31 113.2,-69 109.62,-60.98 111,-51.92 114.11,-43.74\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"117.3,-45.19 118.37,-34.64 110.96,-42.22 117.3,-45.19\"/>\n<text text-anchor=\"middle\" x=\"125.7\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">0.20</text>\n</g>\n<!-- 3&#45;&gt;2 -->\n<g id=\"edge4\" class=\"edge\">\n<title>3&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"black\" d=\"M135.96,-35.56C138.15,-41.33 140.46,-47.89 142.2,-54 144.27,-61.29 146.07,-69.3 147.56,-76.73\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"144.15,-77.54 149.44,-86.72 151.02,-76.24 144.15,-77.54\"/>\n<text text-anchor=\"middle\" x=\"157.7\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\">0.20</text>\n</g>\n<!-- 3&#45;&gt;3 -->\n<g id=\"edge6\" class=\"edge\">\n<title>3&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"black\" d=\"M153.73,-25.75C164.71,-26.49 174.2,-23.91 174.2,-18 174.2,-14.03 169.91,-11.56 163.77,-10.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"163.84,-7.09 153.73,-10.25 163.6,-14.09 163.84,-7.09\"/>\n<text text-anchor=\"middle\" x=\"186.7\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.60</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"267.2\" cy=\"-105\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"267.2\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n</g>\n<!-- 4&#45;&gt;4 -->\n<g id=\"edge7\" class=\"edge\">\n<title>4&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"black\" d=\"M291.73,-112.75C302.71,-113.49 312.2,-110.91 312.2,-105 312.2,-101.03 307.91,-98.56 301.77,-97.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"301.84,-94.09 291.73,-97.25 301.6,-101.09 301.84,-94.09\"/>\n<text text-anchor=\"middle\" x=\"324.7\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.60</text>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<ellipse fill=\"none\" stroke=\"black\" cx=\"382.2\" cy=\"-105\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"382.2\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">test</text>\n</g>\n<!-- 5&#45;&gt;5 -->\n<g id=\"edge8\" class=\"edge\">\n<title>5&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"black\" d=\"M406.73,-112.75C417.71,-113.49 427.2,-110.91 427.2,-105 427.2,-101.03 422.91,-98.56 416.77,-97.59\"/>\n<polygon fill=\"black\" stroke=\"black\" points=\"416.84,-94.09 406.73,-97.25 416.6,-101.09 416.84,-94.09\"/>\n<text text-anchor=\"middle\" x=\"439.7\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\">0.70</text>\n</g>\n</g>\n</svg>\n",
      "text/plain": "<graphviz.graphs.Digraph at 0x12f84b2f0>"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = ['Hello', 'world', 'this', 'is', 'a', 'test']\n",
    "# Example attention matrix (normally this should be output from a model)\n",
    "attention_matrix = [\n",
    "    [0.1, 0.2, 0, 0, 0, 0],\n",
    "    [0.1, 0.3, 0, 0, 0, 0],\n",
    "    [0, 0, 0.5, 0.2, 0.1, 0.1],\n",
    "    [0, 0, 0.2, 0.6, 0.1, 0],\n",
    "    [0, 0, 0.1, 0.1, 0.6, 0.1],\n",
    "    [0, 0, 0, 0, 0.1, 0.7]\n",
    "]\n",
    "visualize_token_flow(tokens, attention_matrix)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-26T02:43:02.406161Z",
     "start_time": "2024-05-26T02:43:01.650728Z"
    }
   },
   "id": "a64ecaf0dc03c57f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d431a681ffd61d72"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
